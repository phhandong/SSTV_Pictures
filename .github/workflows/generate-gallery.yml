name: Generate Gallery Data

on:
  push:
    paths:
      - 'images/**'
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: 'pages'
  cancel-in-progress: false

jobs:
  generate-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      # 1. è°ƒæ•´é¡ºåºï¼šå…ˆå¤„ç†ä¸‹è½½ï¼Œç¡®ä¿å›¾ç‰‡å­˜åœ¨
      - name: Process Feishu Temp Files
        run: |
          mkdir -p images/feishu_tmp
          find images/feishu_tmp -name "*.tmp" | while read tmp_file; do
            # Read content, remove newlines/returns
            content=$(cat "$tmp_file" | tr -d '\n' | tr -d '\r')
            
            # Parse URL and Filename (format: url::filename)
            # Split by double colon ::
            url=${content%::*}
            original_filename=${content##*::}
            
            # Extract extension from original filename (e.g. png from image.png)
            extension="${original_filename##*.}"
            
            filename=$(basename "$tmp_file")
            # Extract target folder name: between first '_' and last '.'
            # Example: file_TargetFolder.tmp -> TargetFolder
            target_key=$(echo "$filename" | sed -n 's/^[^_]*_\(.*\)\.[^.]*$/\1/p')
            
            if [ -n "$target_key" ]; then
              # Find matching directory in images/
              # Use -iname instead of -name for case-insensitive matching (e.g. ARCTICSAT vs Arcticsat)
              target_dir=$(find images -maxdepth 1 -type d -iname "*$target_key*" | head -n 1)
              
              # If target directory not found, use fallback directory
              if [ -z "$target_dir" ]; then
                echo "Target directory matching '$target_key' not found. Using fallback."
                target_dir="images/ğŸ›°No_Matched"
                mkdir -p "$target_dir"
              fi

              # Use the filename extracted from content (after ::)
              save_name="$original_filename"
              
              if [ -f "$target_dir/$save_name" ]; then
                echo "File $target_dir/$save_name already exists. Deleting old file."
                rm "$target_dir/$save_name"
              fi
              
              echo "Downloading $url to $target_dir/$save_name"
              curl -L -o "$target_dir/$save_name" "$url"
              
              if [ $? -eq 0 ]; then
                rm "$tmp_file"
              else
                echo "Failed to download $url"
              fi
            else
              echo "Could not parse target key from $filename"
            fi
          done

      # 2. è°ƒæ•´é¡ºåºï¼šå›¾ç‰‡ä¸‹è½½å®Œæˆåï¼Œå†ç”Ÿæˆ JSON æ•°æ®
      - name: Generate gallery data
        run: |
          python generate_data.py

      # 3. ç»Ÿä¸€æäº¤ï¼šåŒæ—¶æäº¤ä¸‹è½½çš„å›¾ç‰‡å’Œç”Ÿæˆçš„ JSON
      - name: Commit Changes
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          commit_message: 'Automated: Process images and update gallery data'
          file_pattern: 'images/** data/gallery-data.json'
          skip_fetch: true

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: '.'

  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: generate-data
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
